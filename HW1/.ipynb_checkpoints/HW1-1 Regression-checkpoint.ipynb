{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "#from model import *\n",
    "import csv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relative Compactness</th>\n",
       "      <th>Surface Area</th>\n",
       "      <th>Wall Area</th>\n",
       "      <th>Roof Area</th>\n",
       "      <th>Overall Height</th>\n",
       "      <th>Orientation</th>\n",
       "      <th>Glazing Area</th>\n",
       "      <th>Glazing Area Distribution</th>\n",
       "      <th>Heating Load</th>\n",
       "      <th>Cooling Load</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.90</td>\n",
       "      <td>563.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>122.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.84</td>\n",
       "      <td>28.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>763</td>\n",
       "      <td>0.64</td>\n",
       "      <td>784.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>17.88</td>\n",
       "      <td>21.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>764</td>\n",
       "      <td>0.62</td>\n",
       "      <td>808.5</td>\n",
       "      <td>367.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>16.54</td>\n",
       "      <td>16.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>765</td>\n",
       "      <td>0.62</td>\n",
       "      <td>808.5</td>\n",
       "      <td>367.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>16.44</td>\n",
       "      <td>17.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>766</td>\n",
       "      <td>0.62</td>\n",
       "      <td>808.5</td>\n",
       "      <td>367.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>16.48</td>\n",
       "      <td>16.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>767</td>\n",
       "      <td>0.62</td>\n",
       "      <td>808.5</td>\n",
       "      <td>367.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>16.64</td>\n",
       "      <td>16.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Relative Compactness  Surface Area  Wall Area  Roof Area  Overall Height  \\\n",
       "0                    0.98         514.5      294.0     110.25             7.0   \n",
       "1                    0.98         514.5      294.0     110.25             7.0   \n",
       "2                    0.98         514.5      294.0     110.25             7.0   \n",
       "3                    0.98         514.5      294.0     110.25             7.0   \n",
       "4                    0.90         563.5      318.5     122.50             7.0   \n",
       "..                    ...           ...        ...        ...             ...   \n",
       "763                  0.64         784.0      343.0     220.50             3.5   \n",
       "764                  0.62         808.5      367.5     220.50             3.5   \n",
       "765                  0.62         808.5      367.5     220.50             3.5   \n",
       "766                  0.62         808.5      367.5     220.50             3.5   \n",
       "767                  0.62         808.5      367.5     220.50             3.5   \n",
       "\n",
       "     Orientation  Glazing Area  Glazing Area Distribution  Heating Load  \\\n",
       "0              2           0.0                          0         15.55   \n",
       "1              3           0.0                          0         15.55   \n",
       "2              4           0.0                          0         15.55   \n",
       "3              5           0.0                          0         15.55   \n",
       "4              2           0.0                          0         20.84   \n",
       "..           ...           ...                        ...           ...   \n",
       "763            5           0.4                          5         17.88   \n",
       "764            2           0.4                          5         16.54   \n",
       "765            3           0.4                          5         16.44   \n",
       "766            4           0.4                          5         16.48   \n",
       "767            5           0.4                          5         16.64   \n",
       "\n",
       "     Cooling Load  \n",
       "0           21.33  \n",
       "1           21.33  \n",
       "2           21.33  \n",
       "3           21.33  \n",
       "4           28.28  \n",
       "..            ...  \n",
       "763         21.40  \n",
       "764         16.88  \n",
       "765         17.11  \n",
       "766         16.61  \n",
       "767         16.03  \n",
       "\n",
       "[768 rows x 10 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data11 = pd.read_csv(\"EnergyEfficiency_data.csv\")\n",
    "data11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "class NN(object):\n",
    "    def __init__(self, layers = [10 , 20, 1], activations=['sigmoid', 'relu'], usage = 'regression'):\n",
    "        assert(len(layers) == len(activations)+1)\n",
    "        self.layers = layers\n",
    "        self.activations = activations\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        self.usage = usage\n",
    "        for i in range(len(layers)-1):\n",
    "            self.weights.append(np.random.randn(layers[i+1], layers[i]))\n",
    "            self.biases.append(np.random.randn(layers[i+1], 1))\n",
    "\n",
    "    def feedforward(self, x): #x = dim*num\n",
    "        ai = np.copy(x)\n",
    "        z_s = []\n",
    "        a_s = [ai]\n",
    "        for i in range(len(self.weights)):\n",
    "            #activation_function = self.AF(self.activations[i])\n",
    "            z_s.append(self.weights[i].dot(ai) + self.biases[i])\n",
    "            ai = self.AF(self.activations[i])(z_s[-1])\n",
    "            a_s.append(ai)\n",
    "        return (z_s, a_s)\n",
    "\n",
    "    def backpropagation(self,y, z_s, a_s): #y = 1*num\n",
    "        dw = []  # dC/dW\n",
    "        db = []  # dC/dB\n",
    "        deltas = [None] * len(self.weights)  # delta = dC/dZ, error for each layer\n",
    "\n",
    "        #out delta measurement =\n",
    "        delta_out = y- a_s[-1]\n",
    "        #last layer delta\n",
    "        deltas[-1] = delta_out*(self.dAF(self.activations[-1]))(z_s[-1])\n",
    "        #backpro\n",
    "        for i in reversed(range(len(deltas)-1)):\n",
    "            deltas[i] = self.weights[i+1].T.dot(deltas[i+1])*(self.dAF(self.activations[i])(z_s[i]))\n",
    "        batch_size = y.shape[1]\n",
    "        db = [d.dot(np.ones((batch_size,1)))/float(batch_size) for d in deltas]\n",
    "        dw = [d.dot(a_s[i].T)/float(batch_size) for i,d in enumerate(deltas)]\n",
    "        #db = [d.dot(np.ones((batch_size,1))) for d in deltas]\n",
    "        #dw = [d.dot(a_s[i].T) for i,d in enumerate(deltas)]\n",
    "        # return the derivitives respect to weight matrix and biases\n",
    "        #print(db)\n",
    "        #print(dw)\n",
    "        return dw, db\n",
    "\n",
    "    def train(self, x, y, batch_size=10, epochs=100, lr = 0.1): #x = num*dim #y = num*dim\n",
    "        #record cost by epchos\n",
    "        learning_curve = []\n",
    "\n",
    "        #mini batch\n",
    "        #assert(x.shape[0] >= batch_size*epochs)\n",
    "        indices = np.arange(x.shape[0])#debug if 0\n",
    "        np.random.shuffle(indices)\n",
    "        x = x[indices]\n",
    "        y = y[indices]\n",
    "        \n",
    "        for e in range(epochs):\n",
    "            i=0\n",
    "            #print(\"len y  \", len(y))\n",
    "            while(i<len(y)):\n",
    "                x_batch = x[i:i+batch_size]\n",
    "                y_batch = y[i:i+batch_size]\n",
    "                x_batch = x_batch.T\n",
    "                y_batch = y_batch.T\n",
    "                #print(x_batch.shape)\n",
    "                #print(y_batch.shape)\n",
    "                i += batch_size\n",
    "                z_s, a_s = self.feedforward(x_batch)\n",
    "                dw, db = self.backpropagation(y_batch, z_s, a_s)\n",
    "                self.weights = [wi+lr*dwi for wi,dwi in  zip(self.weights, dw)]\n",
    "                self.biases = [bi+lr*dbi for bi,dbi in  zip(self.biases, db)]\n",
    "                loss = np.linalg.norm(a_s[-1]-y_batch)\n",
    "            #if(e%(epochs/10)== 0):\n",
    "            learning_curve.append(loss) #to expand\n",
    "            #print(\"loss = {}\".format(np.linalg.norm(a_s[-1]-y_batch))) #to expand\n",
    "        return learning_curve\n",
    "    @staticmethod\n",
    "    def AF(name):\n",
    "        if(name == 'sigmoid'):\n",
    "            def sig(x):\n",
    "                x = np.clip(x , -500, 500)\n",
    "                return np.exp(x)/(1+np.exp(x))\n",
    "            return sig\n",
    "        elif(name == 'linear'):\n",
    "            return lambda x : x\n",
    "        elif(name == 'relu'):\n",
    "            def relu(x):\n",
    "                y = np.copy(x)\n",
    "                y[y<0] = 0\n",
    "                return y\n",
    "            return relu\n",
    "        else:\n",
    "            print('unknown activation function => linear')\n",
    "            return lambda x: x\n",
    "        \n",
    "    @staticmethod\n",
    "    def dAF(name):\n",
    "        if(name == 'sigmoid'):\n",
    "            def dsig(x):\n",
    "                x = np.clip(x , -500, 500)\n",
    "                sigx = np.exp(x)/(1+np.exp(x))\n",
    "                return sigx*(1-sigx)\n",
    "            return dsig\n",
    "        elif(name == 'linear'):\n",
    "            return lambda x: 1\n",
    "        elif(name == 'relu'):\n",
    "            def drelu(x):\n",
    "                y = np.copy(x)\n",
    "                y[y>=0] = 1\n",
    "                y[y<0] = 0\n",
    "                return y\n",
    "            return drelu\n",
    "        else:\n",
    "            print('unknown activation function => linear derivative')\n",
    "            return lambda x: 1\n",
    "\n",
    "    @staticmethod\n",
    "    def dJ(name):\n",
    "        if(name == 'regression'):\n",
    "            return lambda x, y: y-x\n",
    "        if(name == 'classification'):\n",
    "            return lambda x, y: np.divide(y, x) - np.divide(1 - y, 1 - x)\n",
    "        else:\n",
    "            print('unknown usage => regression')\n",
    "            return lambda x, y: y-x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n",
      "(768, 1)\n"
     ]
    }
   ],
   "source": [
    "#feature label decomposition\n",
    "y = np.asarray([[vec[8]] for vec in data11.values])\n",
    "X = np.delete(data11.values, 8, 1)\n",
    "\n",
    "#normalization\n",
    "s = [ np.mean(dim) for dim in X.T]\n",
    "X = np.asarray([np.divide(x, s) for x in X])\n",
    "\n",
    "#X = X.T\n",
    "#X.shape\n",
    "#y = y.reshape((1,-1))\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26.75465906147244, 9.732416894644885, 7.520872229025116, 7.372671246932387, 6.18767984274754, 5.948790201435306, 8.530993631021527, 5.034409682366257, 5.240282564503181, 5.4548353917473875, 5.298246717732256, 5.178640990920565, 5.218103466189552, 5.297581685137906, 5.26543099040675, 5.293609636773745, 5.2071439532708945, 5.530366665117419, 5.179389169629628, 5.750428540612636, 5.238360599526689, 5.596723092888517, 5.075260715022235, 4.807246155905585, 4.666550865901781, 4.557977823562618, 4.480084151261436, 4.389743199147048, 4.302482155026649, 4.272562160690344, 4.296005254394775, 4.311835317981702, 4.299498493141443, 4.266270139175015, 4.22671367399397, 4.190271861177887, 4.1587459391154935, 4.130452611569075, 4.103572419977999, 4.0769256401939575, 4.049861919837141, 4.022090165875436, 3.9935582802797898, 3.964361549946485, 3.934673895766064, 3.904709280387532, 3.874715861604653, 3.844991483850843, 3.8158959072031613, 3.7878324303494755, 3.7611868150171266, 3.73624253464707, 3.713116690719879, 3.691751789439614, 3.6719591117494907, 3.653480613556402, 3.636041076574646, 3.6193818993323426, 3.6032797046914684, 3.5875546137913648, 3.572071520570528, 3.5567366836156817, 3.541491566000993, 3.5263055434818256, 3.511168679454393, 3.4960853043141515, 3.4810687429023637, 3.4661372566688162, 3.451311104321608, 3.436610548379394, 3.4220546140879695, 3.4076604169163183, 3.3934428988693868, 3.3794148424378947, 3.3655870589772015, 3.351968673254133]\n"
     ]
    }
   ],
   "source": [
    "nn = NN([9, 5, 1],activations=['sigmoid', 'relu'], usage = 'regression')\n",
    "\n",
    "learning_curve = nn.train(X, y, epochs=76, batch_size=10, lr = .1)\n",
    "\n",
    "print(learning_curve)\n",
    "_, a_s = nn.feedforward(X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, a_s = nn.feedforward(X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16.7405923  17.25632534 17.24896789 16.88489008 20.37268925 18.970235\n",
      "  18.77343122 20.9863534  19.21566927 17.44488343 17.87423666 19.19128997\n",
      "  18.08443209 17.57763346 17.24022953 18.29984582 29.69058334 25.8117058\n",
      "  25.03705012 30.23755338 26.62377052 26.84438799 26.7076306  25.77460773\n",
      "   6.14034667  6.44081535  6.27464877  5.9770762   6.19761544  6.50550256\n",
      "   6.32614608  6.04001176  6.29465397  6.61393612  6.42488985  6.13457429\n",
      "   6.74576393  6.96335219  6.8092965   6.42145237 10.1128806  10.39353609\n",
      "  10.10357076  9.60170949  8.45529279  8.71299692  8.3453682   7.90223742\n",
      "  24.97956954 25.38521579 25.17304691 24.4933203  28.66649765 27.35146996\n",
      "  26.87120706 29.42695993 26.92624932 24.61745865 24.92016996 26.94799398\n",
      "  25.28427398 24.65291162 24.29981522 25.40858319 35.04796222 33.94378532\n",
      "  33.07100569 35.86866912 33.785272   34.440207   34.3260656  33.59727115\n",
      "  10.42312544 10.69392843 10.57859315 10.32687357 10.52500626 10.81167608\n",
      "  10.6684854  10.43476546 10.70405086 10.99280561 10.82687197 10.5654063\n",
      "  11.04268079 11.18927016 11.07339637 10.70964429 15.34084674 15.61841347\n",
      "  15.36054227 14.96075156 13.19764376 13.39673933 13.01384112 12.54829886\n",
      "  25.29600772 25.43907448 25.44669508 24.824723   28.85117106 27.57487926\n",
      "  27.21673116 29.61439807 27.56041813 24.94932106 25.39997096 27.61908349\n",
      "  25.80022927 24.99488901 24.68725594 26.02147957 35.28769794 33.82118285\n",
      "  32.89512534 35.94435007 34.24731774 34.78038121 34.66840512 34.13374785\n",
      "  10.75231959 10.99301204 10.95594355 10.83081943 10.85052422 11.10040919\n",
      "  11.04473991 10.93720919 10.92542556 11.16287534 11.10174492 10.97618728\n",
      "  11.60236926 11.74087133 11.73582359 11.4784765  15.50182828 15.75350862\n",
      "  15.59660478 15.31113309 13.41536434 13.62577822 13.24884104 12.95602813\n",
      "  25.51473115 25.85043716 25.37849953 25.07368009 29.73690923 29.46744696\n",
      "  27.79463356 27.04341309 28.50581031 28.07950118 24.78921148 24.97983032\n",
      "  26.94756448 26.1869109  24.82948594 24.27795703 35.92922893 35.95815477\n",
      "  33.81462084 32.66178589 34.45095899 34.8304273  34.73043659 34.39381737\n",
      "  10.85867534 10.99329242 10.95685798 10.81176274 10.98169008 11.09875421\n",
      "  11.08675326 10.91797978 11.14876851 11.26476862 11.25693331 11.07907501\n",
      "  11.32533781 11.47720557 11.38023446 11.26634733 15.47124422 15.56555056\n",
      "  15.54467697 15.20344615 13.19046599 13.28527459 13.04805328 12.64313107\n",
      "  25.93033518 25.76398225 25.6356294  24.94766445 27.80392715 29.78704229\n",
      "  29.04510865 27.24410203 25.830506   28.67445753 27.75075582 24.2117815\n",
      "  24.8542003  26.961002   25.7937021  24.20957489 33.48201533 36.36086902\n",
      "  35.772594   33.26594494 34.60145804 34.64420437 34.46282548 34.17177996\n",
      "  10.86464234 10.93632372 10.84033454 10.68680305 10.97966346 11.07613132\n",
      "  10.9644605  10.82670993 11.15760366 11.243452   11.14162655 11.00637299\n",
      "  11.65066024 11.62801159 11.59288056 11.35026695 15.51781619 15.49668158\n",
      "  15.42305935 15.16677317 13.2690404  13.18446876 12.93709102 12.77105335\n",
      "  25.95544442 25.98527765 25.47133533 25.18673049 28.11410664 27.87868845\n",
      "  29.46735911 28.53488963 25.22624381 25.82524987 28.34839421 27.35153706\n",
      "  25.11723104 24.72423824 26.68011426 25.31485598 33.86332341 33.19607298\n",
      "  35.87463734 35.08128777 34.63809871 34.68932254 34.24556864 33.99696861\n",
      "  10.85758505 10.8450904  10.72926397 10.50802323 10.99892371 10.9664462\n",
      "  10.87664143 10.64245413 11.17590441 11.13901097 11.02866868 10.81140847\n",
      "  11.52711993 11.56403569 11.36992794 11.19080676 15.45062881 15.28796554\n",
      "  15.09474684 14.77203134 13.05033798 12.76765777 12.54699742 12.33230321\n",
      "  28.49004991 28.91881402 28.45770996 28.13269558 32.35168898 30.67321151\n",
      "  30.18929458 33.4286384  30.3866467  27.18594027 27.68149021 30.55185379\n",
      "  27.9906495  27.12136588 26.87682089 28.43338012 39.19852794 37.32632573\n",
      "  36.24968727 40.13155162 37.29815998 38.10013068 37.91066712 37.06888666\n",
      "  12.26041302 12.5047467  12.46917859 12.46230647 12.4249008  12.69513977\n",
      "  12.60874413 12.63592829 12.49937171 12.77041634 12.7277672  12.74305385\n",
      "  13.27486936 13.35750716 13.36655801 13.19768869 17.9335121  18.10265835\n",
      "  17.90454794 17.71098458 14.80226244 14.97963436 14.70481353 14.51678516\n",
      "  28.8730762  29.15071399 29.13420293 28.57650311 32.06915798 30.51984754\n",
      "  30.33627761 33.30980504 30.26747376 27.10967855 27.74303085 30.47600396\n",
      "  27.29956426 26.96729806 26.77706407 27.61056483 39.45217492 37.03533066\n",
      "  36.14531608 40.0879459  37.54169023 38.03615734 37.77844234 37.1050933\n",
      "  12.22434753 12.41061921 12.41625394 12.41394612 12.36692107 12.58014916\n",
      "  12.47347629 12.49778489 12.61133784 12.80335303 12.73599113 12.7584452\n",
      "  13.07735381 13.14174397 13.23338918 13.02355978 17.34239273 17.43985346\n",
      "  17.21775024 16.97083094 14.35832463 14.58072112 14.09348527 14.04058341\n",
      "  29.14584418 29.3771687  29.18863471 28.73501495 32.73115364 31.94710163\n",
      "  30.39029873 29.721189   30.67690542 30.21818899 27.19852654 27.44119048\n",
      "  27.839007   27.33637959 26.84607836 26.41820876 39.75920017 39.94640893\n",
      "  36.9126647  35.588811   37.31886937 37.57405123 37.67449632 37.21282666\n",
      "  12.19083054 12.13760503 12.27134739 12.21580393 12.37773297 12.40591569\n",
      "  12.54735498 12.35389242 12.47700803 12.41918484 12.62408476 12.4939855\n",
      "  12.92960131 13.05852186 13.12199428 13.0725553  16.7088565  16.80380975\n",
      "  17.04794199 16.66127439 13.94294966 13.94415591 13.77303937 13.32049643\n",
      "  29.45431767 29.3887241  29.2413431  28.70891517 30.45287791 33.22930596\n",
      "  32.08828212 30.00321094 28.34617367 31.17677057 30.61408468 26.83711186\n",
      "  26.99041593 28.34705447 27.59398862 26.61247536 36.03174986 40.16099943\n",
      "  39.81141899 35.7457133  37.91719006 37.65674874 37.41845358 37.14470753\n",
      "  12.25164301 12.34041627 12.25545559 12.23722928 12.31562207 12.4250939\n",
      "  12.40244331 12.41634389 12.56754104 12.67815848 12.65288715 12.64542882\n",
      "  13.04247393 12.91912067 13.04849012 12.93593592 16.3961635  16.39922184\n",
      "  16.80926166 16.12560125 14.17354987 14.19362837 13.72764936 13.75256827\n",
      "  29.54723261 29.4558592  29.11287632 28.6842449  30.57104611 30.30962735\n",
      "  32.53430567 30.96690606 27.83469499 28.36618654 30.71073062 29.79381794\n",
      "  27.23843485 26.88377274 28.00561581 26.89678086 37.05946479 36.03500297\n",
      "  39.84130511 39.17683727 37.80091304 37.65361668 36.58007458 36.27783127\n",
      "  12.13602179 12.14891798 12.12796999 11.89503272 12.40631611 12.28695972\n",
      "  12.33062016 12.18213237 12.4844804  12.43819932 12.43177354 12.20053434\n",
      "  12.95495869 12.99710297 12.83714797 12.80954021 16.76213293 16.50450643\n",
      "  16.48180651 16.34396964 13.89356049 13.44972052 13.31668365 13.22971838\n",
      "  33.24998105 33.5317094  33.08215836 32.86283441 35.97477064 34.95350911\n",
      "  34.65509798 37.1546073  34.22204009 30.112427   30.63525796 34.37145116\n",
      "  31.306583   29.2172044  28.9098516  32.20160884 40.17477309 39.44620611\n",
      "  38.87579013 40.8369657  40.07870123 40.61688231 40.66907398 40.43295942\n",
      "  14.51606458 14.65045429 14.62472346 14.6308314  14.61283336 14.76026486\n",
      "  14.70555622 14.73020486 14.60718098 14.7692382  14.74452487 14.7695153\n",
      "  15.25474088 15.27245611 15.26950255 15.16211473 19.45549363 19.41018617\n",
      "  19.23140666 18.85757202 16.4068648  16.38091803 16.23166322 16.13245558\n",
      "  33.37261233 33.59184577 33.77661609 33.38951105 35.5738905  34.58978012\n",
      "  34.22943216 36.72581663 34.16891031 30.25286986 31.36745878 34.55495709\n",
      "  30.4504353  28.61111892 28.97775951 31.80382554 40.35954836 39.60700901\n",
      "  39.16447595 40.81879534 40.24742589 40.62516385 40.63625445 40.4249504\n",
      "  14.48055217 14.60320663 14.60294517 14.58205874 14.59846691 14.73846769\n",
      "  14.71373779 14.72085046 14.62280998 14.7640872  14.78694306 14.75468627\n",
      "  15.17104082 15.20524369 15.30094615 15.18296888 18.48881735 18.71504543\n",
      "  18.55458366 18.21226556 16.41642215 16.36610912 15.94770501 15.89974522\n",
      "  33.51467485 33.73725525 33.77229205 33.50033556 35.18602837 34.49719908\n",
      "  33.72017154 33.03645564 34.23505714 33.85198845 29.80162471 30.59202448\n",
      "  32.67664877 30.77331223 29.67405494 29.19558225 40.50308893 40.67372079\n",
      "  39.05654892 38.35870144 40.21595677 40.41104561 40.51067056 40.40468875\n",
      "  14.4439984  14.37599705 14.52380225 14.49680124 14.51919312 14.45416018\n",
      "  14.61463308 14.49717005 14.62087127 14.56492759 14.73098471 14.70231747\n",
      "  14.95632106 15.11145036 15.19703286 15.17335526 17.58633575 17.42432665\n",
      "  17.96147395 17.76626871 16.04032    16.10739489 15.68905272 15.33657857\n",
      "  33.71434402 33.70385335 33.78151457 33.39814502 34.16762904 36.33670983\n",
      "  35.8157572  34.39074424 31.96447472 34.76905487 34.55517898 30.28852814\n",
      "  29.29076503 32.60172861 31.04462488 28.50558121 38.91415111 40.80299694\n",
      "  40.74114191 39.10159418 40.49760649 40.5459991  40.46760242 40.37430687\n",
      "  14.51830078 14.54667182 14.54530598 14.57013805 14.63385007 14.69756862\n",
      "  14.67701579 14.72162928 14.70364727 14.72181961 14.6986115  14.74615295\n",
      "  15.17149671 15.1445283  15.25060394 15.15546083 18.3510242  18.06827133\n",
      "  18.57097216 18.60904849 16.06991592 15.81514694 15.60866457 15.60314949\n",
      "  33.75548097 33.75065328 33.641063   33.33991542 34.22219474 33.76271124\n",
      "  35.45351585 34.64165962 30.67706705 31.64334337 34.57312732 33.99355057\n",
      "  31.00935156 30.30324885 33.63986145 32.04834386 38.96798812 38.25068074\n",
      "  40.70409353 40.43047658 40.45073948 40.51081858 40.00334342 39.83133891\n",
      "  14.52297005 14.50504728 14.52231751 14.43988151 14.43127114 14.26441256\n",
      "  14.35163719 14.30573532 14.67243053 14.53158925 14.61607734 14.60817949\n",
      "  15.10689595 15.12264511 15.01065857 15.0870671  17.50983545 16.88781562\n",
      "  17.12163052 17.5254021  15.86448071 15.9016587  15.54280754 15.19613766]]\n"
     ]
    }
   ],
   "source": [
    "print(a_s[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_save = nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_w = nn_save.weights\n",
    "good_b = nn_save.biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
